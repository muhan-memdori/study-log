# 내가 만든 서비스는 얼마나 많은 사용자가 이용할 수 있을까? - 1편(성능 테스트란?)

> 출처: https://hyuntaeknote.tistory.com/10

## 성능 테스트를 해야 하는 이유

애플리케이션의 `성능을 측정`한다는 것은 `점진적인 부하를 가하는 과정에서 더 이상 처리량이 증가하지 않을때, 그 수치를 측정하고 해석`하는 것을 의미한다. 성능 테스트의 목적은 

- 현재 애플리케이션이 최대 몇 명의 사용자를 수용할 수 있는지 측정하고, 결과가 목표 수치에 부합하는지 알아내기 위함이다.
- 만약 목표 수치에 부합하지 않을 경우, 어떤 지점에서 병목이 발생하고, 이를 해결하기 위해 무엇을 해야 하는지 분석하여 개선함으로써 최종적으로 서비스가 중단되는 상황 없이 제공될 수 있도록 가용성을 높이기 위함이다.

___

## 성능을 측정하는 기준

Throughput과 Latency를 확인함으로써 서비스의 속도를 알 수 있다.

- `Throughput` : 시간당 처리량을 의미한다. TPS(Transaction Per Second), RPS(Request Per Second)등으로도 불린다. 보통 1초에 처리하는 단위 작업의 수, 1초에 처리하는 HTTP 요청 수를 측정한다.
- `Latency` : 서버가 클라이언트로부터 요청을 받아서 응답을 보내주기까지 걸리는 시간을 말한다. 서비스가 작업을 얼마나 빠르게 처리할 수 있는지를 나타내는 성능 지표로 볼 수 있다.

___

## 결과 수치 해석과 개선

웹 서비스를 간단히 `웹 서버 - WAS(Web Application Server) - DB` 3단계로 나눈다면, 각각의 단계에서의 Throughput과 Latency를 측정함으로써  어느 단계에서 성능이 개선되어야하는지를 판단할 수가 있다.

다음과 같이 성능 테스트의 결과가 도출되었다고 할 때

|                | **Web Server** | **Web Application Server** | **Database** |
| -------------- | -------------- | -------------------------- | ------------ |
| **Throughput** | 500TPS         | 2000TPS                    | 1000TPS      |
| **Latency**    | 200ms          | 50ms                       | 100ms        |



### Throughput

전체 서비스의 Throughput은 세개의 throughput값을 다더한 3500TPS가 아니라 `500TPS`이다. WAS나 DB에서 1초에 2000개 혹은 1000개의 요청을 처리할 수 있다고 하더라도 웹 서버에서 500개만 처리할 수 있다면 500개의 요청이 전체 서비스에서 최대 수용 요청이 될 것이기 때문이다.

따라서 개선해야할 부분은 병목 구간이 되는 웹 서버의 성능이라고 할 수 있다. 개선을 통해 웹 서버의 Troughput의 수치를 2000TPS로 끌어올렸다고 가정할 때 여전히 DB의 수치는 1000TPS이므로 DB가 병목 구간이 되고, 전체 서비스의 Throughput 수치는 1000TPS로 성능이 2배가 되었다고 말할 수 있을 것이다.

### Latency

전체 서비스의 Latency는 `대기 시간을 포함한 각 하위 시스템의 Latency의 총합`이다. 따라서 현재 서비스의 Latency는 `300ms + 대기 시간`이라고 할 수 있다. 

Latency를 개선하기 위해 고려해야할 요소는 굉장히 많다. 하드웨어의 처리 성능, 애플리케이션 로직, 쿼리 인덱스 등 다양한 원인으로 Latency가 발생할 수 있기 때문이다. 심지어 Throughput이 한계점이 도달할 때에도 대기시간이 길어져 Latency에 영향을 준다.

Throughput을 분석할 때와 달리 Latency의 경우, 하나의 하위 시스템 Latency가 줄어들면 전체 서비스의 Latency도 줄어들기 때문에 병목 구간을 찾기보다 Latency가 큰 하위 시스템을 개선하는 것이 서비스의 Latency를 큰 폭을 줄일 수 있는 방법이 된다.

|                | **Web Server** | **Web Application Server** | **Database** |
| -------------- | -------------- | -------------------------- | ------------ |
| **Throughput** | **500**TPS     | **3000**TPS                | **2000**TPS  |
| **Latency**    | 200ms          | **30**ms                   | **50**ms     |

병목 구간이 웹서버로 그대로 지만 WAS의 Latency가 30ms로 줄었고, DB도 50ms로 줄었으므로 전체 Latency가 350ms에서 280ms로 줄었다. 이처럼 병목 지점과 관계없이 각 지점의 Latency 개선은 전체에 영향을 줄 수가 있다.

한편으로는 Throughput을 개선하면 그만큼 수용할 수 있는 요청이 늘어나므로 대기시간이 줄어 Latency를 줄일 수 있는 효과도 볼 수 있다.



